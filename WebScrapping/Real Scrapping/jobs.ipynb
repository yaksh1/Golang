{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "from bs4 import BeautifulSoup\n",
    "import requests\n",
    "from IPython.core.display import display,HTML\n",
    "import time\n",
    "import datetime"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Filter out skills which you do not know\n",
      "Filtering out ['database']\n",
      "Type in the skills you know\n",
      "Filtering in ['sql']\n"
     ]
    }
   ],
   "source": [
    "print('Filter out skills which you do not know')\n",
    "unfamiliar_skills = list(map(str,input('-->').split(',')))\n",
    "print(f'Filtering out {unfamiliar_skills}')\n",
    "# --------------------------------------------------------------\n",
    "print('Type in the skills you know')\n",
    "familiar_skills = list(map(str,input('-->').split(',')))\n",
    "print(f'Filtering in {familiar_skills}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "  \n",
    " \n",
    "url = 'https://www.timesjobs.com/candidate/job-search.html?searchType=personalizedSearch&from=submit&txtKeywords=Analysis&txtLocation='\n",
    "headers = {\"User-Agent\": \"Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/98.0.4758.87 Safari/537.36\",\"Accept-Encoding\": \"gzip, deflate, br\",\"Accept\": \"text/html,application/xhtml+xml,application/xml;q=0.9,image/avif,image/webp,image/apng,*/*;q=0.8,application/signed-exchange;v=b3;q=0.9\",\"Connection\":\"close\",\"Upgrade-Insecure-Requests\": \"1\",}\n",
    "\n",
    "html_text = requests.get(url,headers=headers)\n",
    "soup = BeautifulSoup(html_text.content,'html.parser')\n",
    "soup = BeautifulSoup(soup.prettify(),'html.parser')\n",
    "\n",
    "jobs = soup.find_all('li',class_=\"clearfix job-bx wht-shd-bx\")\n",
    " \n",
    "for index,job in enumerate(jobs):\n",
    "  published_date = job.find('span',class_=\"sim-posted\").span.text.replace('\\r\\n','').replace('  ','').strip()\n",
    "  \n",
    "  if 'few'in published_date:\n",
    "    \n",
    "     field_name= job.find('h2').text.strip()\n",
    "     company_name=job.find('h3',class_='joblist-comp-name').text.replace('\\r\\n','').replace('  ','').strip()\n",
    "     skills = job.find('span',class_=\"srp-skills\").text.replace('\\r\\n','').replace('  ','').strip()\n",
    "     today = datetime.date.today()\n",
    "     # skills = list(skill)\n",
    "     more_info=job.header.h2.a['href']\n",
    "     \n",
    "     import csv\n",
    "     header = ['Field','Company','Skills Required','Link','Date']\n",
    "     data = [field_name,company_name,skills,more_info,today]\n",
    "\n",
    " \n",
    "    #  if all([unfamiliar_skill not in skills for unfamiliar_skill in unfamiliar_skills]) and any([familiar_skill in skills for familiar_skill in familiar_skills]):\n",
    " \n",
    "    #   with open('C:\\\\Users\\\\91635\\\\Desktop\\\\Projects\\\\WebScrapping\\\\Real Scrapping\\\\jobsScrap.csv','w',newline='',encoding='UTF8') as f:\n",
    "    #     writer=csv.writer(f)\n",
    "    #     writer.writerow(header)\n",
    "    #     writer.writerow(data)\n",
    "      \n",
    "         \n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "#|---------------------------------------------------------------------------|#\n",
    "#| Now we are automating the process\n",
    "#|---------------------------------------------------------------------------|#\n",
    "\n",
    "def find_jobs():\n",
    "  url = 'https://www.timesjobs.com/candidate/job-search.html?searchType=personalizedSearch&from=submit&txtKeywords=Analysis&txtLocation='\n",
    "  headers = {\"User-Agent\": \"Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/98.0.4758.87 Safari/537.36\",\"Accept-Encoding\": \"gzip, deflate, br\",\"Accept\": \"text/html,application/xhtml+xml,application/xml;q=0.9,image/avif,image/webp,image/apng,*/*;q=0.8,application/signed-exchange;v=b3;q=0.9\",\"Connection\":\"close\",\"Upgrade-Insecure-Requests\": \"1\",}\n",
    "\n",
    "  html_text = requests.get(url,headers=headers)\n",
    "  soup = BeautifulSoup(html_text.content,'html.parser')\n",
    "  soup = BeautifulSoup(soup.prettify(),'html.parser')\n",
    "\n",
    "  jobs = soup.find_all('li',class_=\"clearfix job-bx wht-shd-bx\")\n",
    "  \n",
    "  for index,job in enumerate(jobs):\n",
    "    published_date = job.find('span',class_=\"sim-posted\").span.text.replace('\\r\\n','').replace('  ','').strip()\n",
    "    \n",
    "    if 'few'in published_date:\n",
    "      \n",
    "      field_name= job.find('h2').text.strip()\n",
    "      company_name=job.find('h3',class_='joblist-comp-name').text.replace('\\r\\n','').replace('  ','').strip()\n",
    "      skills = job.find('span',class_=\"srp-skills\").text.replace('\\r\\n','').replace('  ','').strip()\n",
    "      today = datetime.date.today()\n",
    "      # skills = list(skill)\n",
    "      more_info=job.header.h2.a['href']\n",
    "      \n",
    "      import csv\n",
    "      header = ['Field','Company','Skills Required','Link','Date']\n",
    "      data = [field_name,company_name,skills,more_info,today]\n",
    "\n",
    " \n",
    "      if all([unfamiliar_skill not in skills for unfamiliar_skill in unfamiliar_skills]) and any([familiar_skill in skills for familiar_skill in familiar_skills]):\n",
    "       \n",
    "        with open('C:\\\\Users\\\\91635\\\\Desktop\\\\Projects\\\\WebScrapping\\\\Real Scrapping\\\\jobsScrap.csv','a+',newline='',encoding='UTF8') as f:\n",
    "          writer=csv.writer(f)\n",
    "          writer.writerow(data)\n",
    " \n",
    " "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if __name__ == '__main__':\n",
    "  while True:\n",
    "    find_jobs()\n",
    "    time_wait = 10\n",
    "    time.sleep(time_wait)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "63fd5069d213b44bf678585dea6b12cceca9941eaf7f819626cde1f2670de90d"
  },
  "kernelspec": {
   "display_name": "Python 3.9.6 64-bit",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.6"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
